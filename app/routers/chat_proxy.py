"""
Chat Proxy Router - layout.htmlì˜ /api/chat_stream ìš”ì²­ì„ ds-apië¡œ í”„ë¡ì‹œ
"""
from fastapi import APIRouter, Request, HTTPException, Depends
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import httpx
import json
import asyncio
from datetime import datetime

from app.models import UsageHistory
from app.core.database import get_db
from app.core.config import settings

router = APIRouter(prefix="/api", tags=["chat-proxy"])

# vLLM API URL (Docker ì»¨í…Œì´ë„ˆì—ì„œ host ì ‘ê·¼)
import os
LLM_API_URL = os.getenv("LLM_API_URL", "http://host.docker.internal:8000")


class ChatStreamRequest(BaseModel):
    """layout.htmlì—ì„œ ë³´ë‚´ëŠ” ì±„íŒ… ìš”ì²­"""
    message: str
    session_id: Optional[str] = None  # Optionalë¡œ ë³€ê²½
    user_id: str = "anonymous"
    think_mode: bool = False
    file_ids: List[str] = []
    history: List[Dict[str, Any]] = []


async def save_usage_to_db(
    db: AsyncSession,
    user_id: str,
    session_id: str,
    question: str,
    answer: str,
    conversation_title: Optional[str] = None,
    thinking_content: Optional[str] = None
):
    """usage_historyì— ëŒ€í™” ì €ì¥"""
    try:
        # í•´ë‹¹ ì„¸ì…˜ì˜ ì²« ëŒ€í™”ì¸ì§€ í™•ì¸
        if not conversation_title:
            query = select(UsageHistory).filter(
                UsageHistory.session_id == session_id
            ).limit(1)
            result = await db.execute(query)
            existing = result.scalar_one_or_none()

            # ì²« ëŒ€í™”ë¼ë©´ ì§ˆë¬¸ìœ¼ë¡œ ì œëª© ìƒì„±
            if not existing:
                conversation_title = question[:50] + "..." if len(question) > 50 else question

        # ìƒˆ ë ˆì½”ë“œ ìƒì„±
        usage_record = UsageHistory(
            user_id=user_id,
            session_id=session_id,
            conversation_title=conversation_title,
            question=question,
            answer=answer,
            thinking_content=thinking_content,  # thinking ë‚´ìš© ì €ì¥
            model_name="ex-GPT",
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )

        db.add(usage_record)
        await db.commit()

        print(f"âœ… Usage saved to DB: user_id={user_id}, session_id={session_id}")

    except Exception as e:
        print(f"âŒ Failed to save usage to DB: {e}")
        await db.rollback()


@router.post("/chat_stream")
async def chat_stream_proxy(
    request: ChatStreamRequest,
    db: AsyncSession = Depends(get_db),
    raw_request: Request = None
):
    """
    layout.htmlì˜ ì±„íŒ… ìš”ì²­ì„ ds-apië¡œ í”„ë¡ì‹œí•˜ê³  ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°
    ë™ì‹œì— usage_historyì— ì €ì¥
    """

    # session_idê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„± (user_id + timestamp)
    if not request.session_id:
        import time
        request.session_id = f"{request.user_id}_session_{int(time.time())}"

    # vLLM OpenAI í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    messages = []

    # historyê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if request.history:
        for msg in request.history:
            if isinstance(msg, dict):
                messages.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})

    # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
    messages.append({"role": "user", "content": request.message})

    # vLLM OpenAI í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (thinking ëª¨ë“œ ì§€ì›)
    llm_payload = {
        "model": "default-model",
        "messages": messages,
        "stream": True,
        "max_tokens": 2000,
        "temperature": 0.7
    }

    # Think mode í™œì„±í™” (DeepSeek-R1 ë“± thinking ì§€ì› ëª¨ë¸ìš©)
    if request.think_mode:
        # vLLM extra_bodyë¡œ ì „ë‹¬
        llm_payload["extra_body"] = {
            "enable_thinking": True,
            "thinking_budget": 2000  # thinking í† í° ì˜ˆì‚°
        }
        print(f"ğŸ§  Think mode í™œì„±í™”: {request.think_mode}")

    # ì‘ë‹µ ë°ì´í„° ëˆ„ì  (DB ì €ì¥ìš©)
    accumulated_response = ""
    accumulated_thinking = ""  # thinking ë‚´ìš© ë³„ë„ ì €ì¥
    is_thinking = False  # í˜„ì¬ thinking ì²˜ë¦¬ ì¤‘ì¸ì§€ ì—¬ë¶€

    async def stream_and_save():
        nonlocal accumulated_response, accumulated_thinking, is_thinking

        try:
            # LLM APIë¡œ ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ (follow_redirects=True ì¶”ê°€)
            async with httpx.AsyncClient(timeout=120.0, follow_redirects=True) as client:
                async with client.stream(
                    "POST",
                    f"{LLM_API_URL}/v1/chat/completions",
                    json=llm_payload,
                    headers={"Content-Type": "application/json"}
                ) as response:

                    if response.status_code != 200:
                        error_msg = f"LLM API ì˜¤ë¥˜: {response.status_code}"
                        yield f"data: {json.dumps({'content': error_msg}, ensure_ascii=False)}\n\n"
                        yield "data: [DONE]\n\n"

                        # ì˜¤ë¥˜ë„ DBì— ì €ì¥
                        await save_usage_to_db(
                            db=db,
                            user_id=request.user_id,
                            session_id=request.session_id,
                            question=request.message,
                            answer=error_msg
                        )
                        return

                    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì „ë‹¬ ë° íŒŒì‹± (vLLM OpenAI í˜¸í™˜ í˜•ì‹)
                    async for line in response.aiter_lines():
                        if line:
                            # ì‘ë‹µ ë°ì´í„° íŒŒì‹± ë° ëˆ„ì 
                            if line.startswith("data: "):
                                data_str = line[6:].strip()
                                if data_str == "[DONE]":
                                    yield "data: [DONE]\n\n"
                                    break

                                try:
                                    data = json.loads(data_str)

                                    # vLLM í˜•ì‹: choices[0].delta.content ì¶”ì¶œ
                                    if "choices" in data and len(data["choices"]) > 0:
                                        delta = data["choices"][0].get("delta", {})
                                        token = delta.get("content", "")

                                        if token:
                                            # Thinking íƒœê·¸ ê°ì§€ ë° ë¶„ë¦¬
                                            if '<think>' in token:
                                                is_thinking = True

                                            if is_thinking:
                                                accumulated_thinking += token
                                                if '</think>' in token:
                                                    is_thinking = False
                                            else:
                                                accumulated_response += token

                                            # layout.htmlì´ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (type: "token" í•„ë“œ ì¶”ê°€)
                                            yield f"data: {json.dumps({'type': 'token', 'content': token}, ensure_ascii=False)}\n\n"

                                except json.JSONDecodeError:
                                    pass

            # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ DBì— ì €ì¥
            # ì œëª© ìƒì„±ìš© ì„¸ì…˜ì€ DBì— ì €ì¥í•˜ì§€ ì•ŠìŒ
            if request.session_id and request.session_id.startswith('title_gen_'):
                print(f"â­ï¸ ì œëª© ìƒì„± ì„¸ì…˜ ({request.session_id}) - DB ì €ì¥ ìƒëµ")
            elif accumulated_response or accumulated_thinking:
                # ì‘ë‹µì´ ìˆê±°ë‚˜ thinkingì´ ìˆìœ¼ë©´ ì €ì¥
                # thinking íƒœê·¸ ì œê±° (ë‚´ìš©ë§Œ ì €ì¥)
                clean_thinking = accumulated_thinking.replace('<think>', '').replace('</think>', '').strip()

                await save_usage_to_db(
                    db=db,
                    user_id=request.user_id,
                    session_id=request.session_id,
                    question=request.message,
                    answer=accumulated_response.strip(),
                    thinking_content=clean_thinking if clean_thinking else None
                )
                print(f"ğŸ’¾ DB ì €ì¥ ì™„ë£Œ: answer={len(accumulated_response)} chars, thinking={len(clean_thinking)} chars")

        except Exception as e:
            error_msg = f"í”„ë¡ì‹œ ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ Chat stream proxy error: {e}")
            yield f"data: {json.dumps({'content': error_msg}, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"

            # ì˜¤ë¥˜ë„ DBì— ì €ì¥
            await save_usage_to_db(
                db=db,
                user_id=request.user_id,
                session_id=request.session_id,
                question=request.message,
                answer=error_msg
            )

    return StreamingResponse(
        stream_and_save(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.get("/chat/sessions")
async def get_chat_sessions(
    user_id: Optional[str] = None,
    db: AsyncSession = Depends(get_db)
):
    """
    ì‚¬ìš©ìì˜ ëŒ€í™” ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ (ì‚¬ì´ë“œë°”ìš©)
    ì œëª© ìƒì„±ìš© ì„¸ì…˜(title_gen_)ì€ ì œì™¸

    Returns:
        List of unique sessions with their titles and latest message time
    """
    from sqlalchemy import func, distinct

    # ê° ì„¸ì…˜ì˜ ì²« ë©”ì‹œì§€(ëŒ€í™” ì œëª©)ì™€ ìµœì‹  ì‹œê°„ ì¡°íšŒ
    # ì œëª© ìƒì„±ìš© ì„¸ì…˜ ì œì™¸
    query = select(
        UsageHistory.session_id,
        UsageHistory.conversation_title,
        func.max(UsageHistory.created_at).label('latest_time'),
        func.count(UsageHistory.id).label('message_count')
    ).filter(
        ~UsageHistory.session_id.like('title_gen_%')  # title_gen_ ì„¸ì…˜ ì œì™¸
    ).group_by(
        UsageHistory.session_id,
        UsageHistory.conversation_title
    ).order_by(
        func.max(UsageHistory.created_at).desc()
    )

    if user_id:
        query = query.filter(UsageHistory.user_id == user_id)

    result = await db.execute(query)
    sessions = result.all()

    return {
        "sessions": [
            {
                "session_id": session.session_id,
                "title": session.conversation_title or "ëŒ€í™” ì œëª© ì—†ìŒ",
                "latest_time": session.latest_time.isoformat() if session.latest_time else None,
                "message_count": session.message_count
            }
            for session in sessions
        ]
    }


@router.get("/chat/sessions/{session_id}")
async def get_session_messages(
    session_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    íŠ¹ì • ì„¸ì…˜ì˜ ëª¨ë“  ë©”ì‹œì§€ ì¡°íšŒ
    """
    from sqlalchemy import asc

    query = select(UsageHistory).filter(
        UsageHistory.session_id == session_id
    ).order_by(asc(UsageHistory.created_at))

    result = await db.execute(query)
    messages = result.scalars().all()

    return {
        "session_id": session_id,
        "messages": [
            {
                "id": msg.id,
                "question": msg.question,
                "answer": msg.answer,
                "thinking_content": msg.thinking_content,  # thinking í¬í•¨
                "created_at": msg.created_at.isoformat() if msg.created_at else None
            }
            for msg in messages
        ]
    }


@router.delete("/chat/sessions/{session_id}")
async def delete_session(
    session_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    íŠ¹ì • ì„¸ì…˜ì˜ ëª¨ë“  ë©”ì‹œì§€ ì‚­ì œ
    """
    from sqlalchemy import delete as sql_delete

    # í•´ë‹¹ ì„¸ì…˜ì˜ ëª¨ë“  ë©”ì‹œì§€ ì‚­ì œ
    delete_query = sql_delete(UsageHistory).filter(
        UsageHistory.session_id == session_id
    )

    result = await db.execute(delete_query)
    await db.commit()

    deleted_count = result.rowcount

    print(f"ğŸ—‘ï¸ ì„¸ì…˜ ì‚­ì œ: {session_id}, {deleted_count}ê°œ ë©”ì‹œì§€ ì‚­ì œë¨")

    return {
        "session_id": session_id,
        "deleted_count": deleted_count,
        "message": "Session deleted successfully"
    }


class UpdateSessionTitleRequest(BaseModel):
    """ì„¸ì…˜ ì œëª© ì—…ë°ì´íŠ¸ ìš”ì²­"""
    session_id: str
    title: str


@router.patch("/chat/sessions/{session_id}/title")
async def update_session_title(
    session_id: str,
    request: UpdateSessionTitleRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    íŠ¹ì • ì„¸ì…˜ì˜ ëŒ€í™” ì œëª© ì—…ë°ì´íŠ¸
    """
    from sqlalchemy import update

    # í•´ë‹¹ ì„¸ì…˜ì˜ ëª¨ë“  ë ˆì½”ë“œì˜ conversation_title ì—…ë°ì´íŠ¸
    update_query = update(UsageHistory).where(
        UsageHistory.session_id == session_id
    ).values(
        conversation_title=request.title,
        updated_at=datetime.utcnow()
    )

    result = await db.execute(update_query)
    await db.commit()

    updated_count = result.rowcount

    print(f"ğŸ“ ì„¸ì…˜ ì œëª© ì—…ë°ì´íŠ¸: {session_id}, ì œëª©='{request.title}', {updated_count}ê°œ ë ˆì½”ë“œ ì—…ë°ì´íŠ¸ë¨")

    return {
        "session_id": session_id,
        "title": request.title,
        "updated_count": updated_count,
        "message": "Session title updated successfully"
    }


class STTConversationRequest(BaseModel):
    """STT ëŒ€í™” ì €ì¥ ìš”ì²­"""
    user_id: str
    session_id: str
    question: str  # "STT ì „ì‚¬í•´ì¤˜: filename.mp3"
    answer: str  # AI ë¶„ì„ íšŒì˜ë¡
    thinking_content: Optional[str] = None  # ìŒì„± ì „ì‚¬ ë‚´ìš©
    response_time: Optional[float] = None
    usage_metadata: Optional[Dict[str, Any]] = None


@router.post("/stt/save_conversation")
async def save_stt_conversation(
    request: STTConversationRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    STT ëŒ€í™” ë‚´ì—­ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    layout.htmlì˜ processVoiceToChat()ì—ì„œ í˜¸ì¶œ
    """
    try:
        # ëŒ€í™” ì œëª© ìƒì„± (ì²« ëŒ€í™”ì¸ ê²½ìš°)
        query = select(UsageHistory).filter(
            UsageHistory.session_id == request.session_id
        ).limit(1)
        result = await db.execute(query)
        existing = result.scalar_one_or_none()

        conversation_title = None
        if not existing:
            # STT ìš”ì²­ì„ì„ ëª…ì‹œí•œ ì œëª©
            conversation_title = f"ğŸ¤ {request.question[:50]}"

        # ìƒˆ ë ˆì½”ë“œ ìƒì„±
        usage_record = UsageHistory(
            user_id=request.user_id,
            session_id=request.session_id,
            conversation_title=conversation_title,
            question=request.question,
            answer=request.answer,
            thinking_content=request.thinking_content,
            response_time=request.response_time,
            model_name="ex-GPT-STT",  # STTì„ì„ ëª…ì‹œ
            usage_metadata=request.usage_metadata,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )

        db.add(usage_record)
        await db.commit()
        await db.refresh(usage_record)

        print(f"âœ… STT conversation saved to DB: id={usage_record.id}, session_id={request.session_id}")

        return {
            "success": True,
            "id": usage_record.id,
            "message": "STT ëŒ€í™”ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
        }

    except Exception as e:
        print(f"âŒ Failed to save STT conversation to DB: {e}")
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"STT ëŒ€í™” ì €ì¥ ì‹¤íŒ¨: {str(e)}")
